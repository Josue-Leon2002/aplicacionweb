# -*- coding: utf-8 -*-
"""RETO_IA_FINAL_JJJ_NOSUP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12CvN4bZoIcrbypJhrvwXB8RKgRaT_vW2
"""

!pip install pandas scikit-learn matplotlib seaborn numpy

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, classification_report, confusion_matrix
from sklearn.decomposition import PCA

from google.colab import files
uploaded = files.upload()

import io
import pandas as pd
df = pd.read_csv(io.BytesIO(uploaded['dataset_transacciones_sintetico.csv']))

binary_vars = ['is_foreign', 'is_online']
ordinal_vars = ['customer_segment', 'customer_tenure_level']
nominal_vars = ['device_type', 'merchant_category', 'email_domain_type', 'txn_hour_category']
numeric_vars = ['amount', 'customer_age', 'account_age_days', 'location_risk_score',
                'merchant_risk_score', 'num_cards_linked', 'avg_tx_amount_last_30d',
                'failed_login_attempts_7d', 'amount_deviation', 'transaction_day']

# Configurar ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('binary', OrdinalEncoder(), binary_vars),
        ('ordinal', OrdinalEncoder(categories=[['low', 'medium', 'high'], ['new', 'regular', 'loyal']]), ordinal_vars),
        ('nominal', OneHotEncoder(handle_unknown='ignore'), nominal_vars),  # Remove sparse=False
        ('numeric', StandardScaler(), numeric_vars)
    ],
    remainder='drop'  # Ignorar columnas no especificadas
)

# Aplicar preprocesamiento
X_processed = preprocessor.fit_transform(df)

# Aplicar PCA para visualización
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_processed)

df.head()

# Método del codo para elegir K
wcss = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_processed)
    wcss.append(kmeans.inertia_)

# Graficar método del codo
plt.figure(figsize=(10, 5))
plt.plot(range(2, 11), wcss, marker='o')
plt.xlabel('Número de Clusters (K)')
plt.ylabel('WCSS (Inercia)')
plt.title('Método del Codo para K-Means')
plt.show()

# Elegir K basado en el gráfico y entrenar modelo (ejemplo con K=2)
kmeans = KMeans(n_clusters=2, random_state=42)
clusters = kmeans.fit_predict(X_processed)

# Evaluar con Silhouette Score
print(f"Silhouette Score: {silhouette_score(X_processed, clusters):.2f}")

# Analizar distribución de fraudes en clusters
df['cluster'] = clusters
fraud_distribution = df.groupby('cluster')['is_fraud'].mean().reset_index()
print(fraud_distribution)

# Calcular distancia para elegir eps (usando NearestNeighbors)
from sklearn.neighbors import NearestNeighbors
neighbors = NearestNeighbors(n_neighbors=5)
neighbors_fit = neighbors.fit(X_processed)
distances, indices = neighbors_fit.kneighbors(X_processed)
distances = np.sort(distances[:, -1], axis=0)

# Graficar distancia para elegir eps
plt.figure(figsize=(10, 5))
plt.plot(distances)
plt.xlabel('Puntos')
plt.ylabel('Distancia al 5to vecino')
plt.title('Método para Elegir eps en DBSCAN')
plt.show()

# Entrenar DBSCAN (ejemplo con eps=3 y min_samples=5)
dbscan = DBSCAN(eps=3, min_samples=5)
outliers = dbscan.fit_predict(X_processed)

# Identificar outliers (fraudes)
df['outlier'] = np.where(outliers == -1, 1, 0)  # -1 = outlier

# Evaluar resultados usando is_fraud
print(classification_report(df['is_fraud'], df['outlier']))
print("Matriz de Confusión:\n", confusion_matrix(df['is_fraud'], df['outlier']))

# Crear DataFrame para visualización
df_pca = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])
df_pca['cluster'] = clusters
df_pca['outlier'] = df['outlier']
df_pca['is_fraud'] = df['is_fraud']

# Graficar K-Means
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='cluster', palette='viridis')
plt.title('Clusters de K-Means')

# Graficar DBSCAN (outliers en rojo)
plt.subplot(1, 2, 2)
sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='outlier', palette={0: 'blue', 1: 'red'})
plt.title('Outliers de DBSCAN (Fraudes)')
plt.show()

# Graficar fraudes reales vs. clusters/outliers
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df_pca, x='PC1', y='PC2', hue='is_fraud', palette={0: 'gray', 1: 'red'})
plt.title('Transacciones Fraudulentas Reales')
plt.show()

# Para K-Means: Centroides de clusters
centroids = pd.DataFrame(
    kmeans.cluster_centers_,
    columns=preprocessor.get_feature_names_out()
)
print("Centroides de Clusters:\n", centroids)

# Para DBSCAN: Comparar estadísticas de outliers vs. no outliers
outlier_stats = df.groupby('outlier')[numeric_vars].mean()
print("Diferencias en Medias (Outliers vs. No Outliers):\n", outlier_stats)

fraud_percentage = df['is_fraud'].mean() * 100
print(f"Porcentaje de fraudes: {fraud_percentage:.2f}%")

